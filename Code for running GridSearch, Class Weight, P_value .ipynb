{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825957a7-fe8f-4693-a0fc-09a1291ea258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d0db2-8fa5-4e5c-b178-1214f80ba1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d346d9b-5470-4d26-9cd7-6c8b3b0cb5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chọn biến mục tiêu\n",
    "target = 'loan_status'\n",
    "model_features = list(set(df.columns).difference({target}))\n",
    "\n",
    "X = df[model_features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77763e8b-2dad-4bbe-8ae4-66ce990e0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf360804-826d-4c8f-97ac-77588f755710",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a223f-57c3-42c1-89e2-b6067ed45ae0",
   "metadata": {},
   "source": [
    "##### GridSearch for Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34876be0-fa6d-4131-84ba-613f23a7a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_for_Gini(x_set, y_set, steps):\n",
    "    lr = LogisticRegression(solver='newton-cg', random_state = 0)\n",
    "    \n",
    "    #Setting the range for class weights\n",
    "    weights = np.linspace(0.0,0.99,20)\n",
    "    \n",
    "    #Creating a dictionary grid for grid search\n",
    "    param_grid = {'class_weight': [{0:1-x, 1:x} for x in weights]}\n",
    "    \n",
    "    #Fitting grid search to the train data with 5 folds\n",
    "    gridsearch = GridSearchCV(estimator= lr, \n",
    "                              param_grid= param_grid,\n",
    "                              cv=StratifiedKFold(), \n",
    "                              n_jobs=-1, \n",
    "                              scoring='roc_auc', \n",
    "                              verbose=2).fit(x_set, y_set)\n",
    "    \n",
    "\n",
    "    # Tạo bảng kết quả gridsearch gồm weights và scores\n",
    "    weigh_data = pd.DataFrame({'score': gridsearch.cv_results_['mean_test_score'], 'weight': weights})\n",
    "    #Ploting the results\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plot = sns.lineplot(x = weigh_data['weight'], y = weigh_data['score'])  # set x-axis là weight, y-axis là score\n",
    "    plt.xlabel('Weight for class 1')\n",
    "    plt.ylabel('AUC score')\n",
    "    plt.xticks([round(i/10,1) for i in range(0,11,1)])\n",
    "    plt.title('Scoring for different class weights', fontsize=24)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073feb0-2df7-47a6-8454-7dd214290054",
   "metadata": {},
   "source": [
    "##### Finding optimal threshold for f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b7441-f0fa-466a-bf54-2a924d965513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do parameter threshold không có sẵn nên em chạy thủ công bằng vòng for :)))\n",
    "threshold = np.linspace(0, 0.99, 20)       #tạo range cần chạy cho threshold, trong đó 20 là số bước nhảy\n",
    "for threshold in threshold:\n",
    "    # xây mô hình\n",
    "    lr = LogisticRegression(solver='newton-cg', random_state = 0)\n",
    "    lr.fit(x_train, y_train)\n",
    "    \n",
    "    # Predicting on the test data\n",
    "    pred_test = lr.predict_proba(x_test)\n",
    "    \n",
    "    pred_test = pd.DataFrame(pred_test,\n",
    "                         columns = ['0', '1'])     # Tạo DataFrame của kết quả xác suất ước lượng\n",
    "    # convert sang giá trị 1 hoặc 0 dựa trên threshold\n",
    "    pred_test_binary = pd.DataFrame(np.where(pred_test['1'] >= threshold, 1, 0), columns = ['1'])\n",
    "    #f1 score\n",
    "    f1.append(f1_score(y_test, pred_test_binary))\n",
    "    \n",
    "    # tạo bảng kết quả gridsearch\n",
    "    f1 = pd.DataFrame(f1, columns = ['score'])       \n",
    "    f1['threshold'] = threshold\n",
    "    # Plot the results\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.lineplot(x = f1['threshold'], y = f1['score'])    #set x_axis = threshold, y-axis = f1_score\n",
    "    plt.xlabel('Weight for class 1')\n",
    "    plt.ylabel('f1_score')\n",
    "    plt.xticks([round(i/10,1) for i in range(0,11,1)])\n",
    "    plt.title('f1_score for different threshold', fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508c6fd-96d7-425e-9b8f-fa6ad026d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_test, pred_test_binary):    \n",
    "    \n",
    "    # Creating a confusion matrix\n",
    "    con_mat = confusion_matrix(y_test, pred_test_binary)\n",
    "    con_mat = pd.DataFrame(con_mat, range(2), range(2))\n",
    "   \n",
    "    #Ploting the confusion matrix\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.set(font_scale=1.5) \n",
    "    sns.heatmap(con_mat, annot=True, annot_kws={\"size\": 16}, fmt='g', cmap='Blues', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb687bf-ec18-432e-a92c-4ac5daf72c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6de4cb4-22e7-4d37-bfd9-266ffd545188",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91798416-f2c1-49bd-8491-a5f88b33c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(w1, threshold):         # w1: weight of class 1\n",
    "    lr = LogisticRegression(solver='newton-cg', class_weight={0: 1-w1, 1: w1}, random_state = 0)     \n",
    "    lr.fit(x_train, y_train)            # xây mô hình\n",
    "    \n",
    "    # Predicting on the test data\n",
    "    pred_test = lr.predict_proba(x_test)\n",
    "    pred_test = pd.DataFrame(pred_test,\n",
    "                         columns = ['0', '1'])      # Tạo DataFrame của kết quả xác suất ước lượng\n",
    "    \n",
    "    # convert sang giá trị 1 hoặc 0 dựa trên threshold\n",
    "    pred_test_binary = pd.DataFrame(np.where(pred_test['1'] >= threshold, 1, 0), columns = ['1']) \n",
    "    #Calculating and printing the f1 score \n",
    "    print('The f1 score for the testing data:', f1_score(y_test, pred_test_binary))\n",
    "    print('The Gini coefficient for the testing data:', 2*roc_auc_score(y_test, pred_test['1']) - 1)\n",
    "\n",
    "    #Ploting the confusion matrix\n",
    "    conf_matrix(y_test, pred_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb862c-5732-43bf-b17e-be89a89eeedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b45c4e4e-0643-431d-b6d5-72298d2f8ab7",
   "metadata": {},
   "source": [
    "### Finding P-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d36b4-8f8b-4dba-b748-e54913639ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04713d61-8487-4c76-881c-26b53f2bf674",
   "metadata": {},
   "source": [
    "#### Methodology\n",
    "\n",
    "\\begin{equation}\n",
    "P_{value} = P(Z > |z|)\n",
    "\\end{equation}\n",
    "where,\\\n",
    "Z ~ Normal(0,1)\\\n",
    "z = Estimated Coef/standard error(s.e)\n",
    "\n",
    "\n",
    "##### Calculate standard error\n",
    "\\begin{equation}\n",
    "s.e = \\sqrt{(X^T\\hat{W}X)^{-1}}\n",
    "\\end{equation}\n",
    "\n",
    "X là ma trận gồm cột số 1 và tập X_train\\\n",
    "$X^T$ là transpose của ma trận X\\\n",
    "W là ma trận 0 và có đường chéo là $\\hat{y}(1-\\hat{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607d86a-ff08-45df-b114-8d14996f4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[model_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534391f-8832-4acf-b969-e576b2c01908",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.transform(df[model_features])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc7d1d-2c11-456c-aacd-fa58e043ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb9ab9-5d26-4624-9f20-ad38540b5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_set là tập train\n",
    "# pred_set là cột giá trị ước lượng dựa trên tập train, KHÔNG DỰA TRÊN TẬP TEST\n",
    "# model: tên model\n",
    "def summary_model(x_set, pred_set, model):                                    \n",
    "    #tạo ma trận X\n",
    "    X_design = np.hstack([np.ones((len(x_set), 1)), x_set])    \n",
    "    \n",
    "    # Tạo ma trận 0 có đường chéo là y(1-y)\n",
    "    W = np.diagflat(pred_set[:, 1]*(1-pred_set[:, 1]))\n",
    "\n",
    "    # Covariance matrix = X^T * W * X\n",
    "    covLogit = np.linalg.pinv(X_design.T @ V @ X_design)\n",
    "    \n",
    "    # Standard errors\n",
    "    standard_error = np.sqrt(np.diag(covLogit))\n",
    "    \n",
    "    #Create summary table\n",
    "    summary_table = pd.DataFrame(model.coef_.T, columns = ['Coef'])             # Tạo bảng các estimated coef\n",
    "    summary_table.set_index(pd.DataFrame(x_set).columns, inplace = True)        # set index là tên columns\n",
    "    summary_table['s.e'] = standard_error[1:,]                                  # Thêm cột standard error\n",
    "    summary_table['z'] = summary_table['Coef']/summary_table['s.e']             # Thêm cột z nhỏ, z = beta/s.e\n",
    "    summary_table['p_value'] = stats.norm.cdf(-abs(summary_table['z'])) * 2     # Tính p-value từ z nhỏ\n",
    "    return summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1fbb3-7d2a-42bb-8798-045c9741f796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691937fb-e067-4d8a-99c6-5463573d5f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
